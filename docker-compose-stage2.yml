version: "2"

services:
  datanode:
    image: bde2020/hadoop-datanode:1.0.0-hadoop2.7.1
    container_name: datanode
    networks:
      - sparklify
    volumes:
      - ./data/datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop-hive.env
    restart: always
  spark-worker:
    image: bde2020/spark-worker:2.0.0-hadoop2.7-hive
    container_name: spark-worker
    networks:
      - sparklify
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    ports:
      - "8081:8081"
    env_file:
      - ./hadoop-hive.env
    restart: always
  hive-metastore:
    image: bde2020/hive:2.1.0-postgresql-metastore
    container_name: hive-metastore
    networks:
      - sparklify
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    restart: always

networks:
  sparklify:
    external:
      name: sparklify
